{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import fenic as fc\n",
    "\n",
    "# 1. Configure session with semantic capabilities\n",
    "config = fc.SessionConfig(\n",
    "    app_name=\"podcast_summarization\",\n",
    "    semantic=fc.SemanticConfig(\n",
    "        language_models={\n",
    "            \"mini\": fc.OpenAIModelConfig(\n",
    "                model_name=\"gpt-4o-mini\",\n",
    "                rpm=500,\n",
    "                tpm=200_000,\n",
    "            )\n",
    "        }\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Create session\n",
    "session = fc.Session.get_or_create(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded raw JSON files as text strings\n",
      "Metadata text length: 3395 characters\n",
      "Transcript text length: 5274252 characters\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(\"data\")\n",
    "\n",
    "# Read metadata file as text\n",
    "with open(data_dir / \"lex_ai_cursor_team_meta.json\", \"r\") as f:\n",
    "    meta_text = f.read()\n",
    "\n",
    "# Read transcript file as text\n",
    "with open(data_dir / \"lex_ai_cursor_team.json\", \"r\") as f:\n",
    "    transcript_text = f.read()\n",
    "\n",
    "print(\"Loaded raw JSON files as text strings\")\n",
    "print(f\"Metadata text length: {len(meta_text)} characters\")\n",
    "print(f\"Transcript text length: {len(transcript_text)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrames created with raw text content:\n",
      "- Metadata DataFrame: 1 row with JSON text\n",
      "- Transcript DataFrame: 1 row with JSON text\n",
      "\n",
      "Content overview:\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ file_name                    â”† content_type â”† content_length â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ lex_ai_cursor_team_meta.json â”† metadata     â”† 3395           â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ file_name               â”† content_type â”† content_length â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ lex_ai_cursor_team.json â”† transcript   â”† 5274252        â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "# 3. Create DataFrames with raw text content\n",
    "# Metadata DataFrame - single row with raw JSON text\n",
    "meta_data = [{\n",
    "    \"file_name\": \"lex_ai_cursor_team_meta.json\",\n",
    "    \"content\": meta_text,\n",
    "    \"content_type\": \"metadata\"\n",
    "}]\n",
    "meta_df = session.create_dataframe(meta_data)\n",
    "\n",
    "# Transcript DataFrame - single row with raw JSON text\n",
    "transcript_data = [{\n",
    "    \"file_name\": \"lex_ai_cursor_team.json\",\n",
    "    \"content\": transcript_text,\n",
    "    \"content_type\": \"transcript\"\n",
    "}]\n",
    "transcript_df = session.create_dataframe(transcript_data)\n",
    "\n",
    "print(\"\\nDataFrames created with raw text content:\")\n",
    "print(\"- Metadata DataFrame: 1 row with JSON text\")\n",
    "print(\"- Transcript DataFrame: 1 row with JSON text\")\n",
    "\n",
    "# Show content lengths\n",
    "print(\"\\nContent overview:\")\n",
    "meta_df.select(\n",
    "    fc.col(\"file_name\"),\n",
    "    fc.col(\"content_type\"),\n",
    "    fc.text.length(fc.col(\"content\")).alias(\"content_length\")\n",
    ").show()\n",
    "\n",
    "transcript_df.select(\n",
    "    fc.col(\"file_name\"),\n",
    "    fc.col(\"content_type\"),\n",
    "    fc.text.length(fc.col(\"content\")).alias(\"content_length\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 4: Processing Metadata ===\n",
      "Metadata converted to JSON type:\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ file_name                    â”† content_type â”† json_data                                          â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ lex_ai_cursor_team_meta.json â”† metadata     â”† {                                                  â”‚\n",
      "â”‚                              â”†              â”† \"title\": \"#447 â€“ Cursor Team: Future of            â”‚\n",
      "â”‚                              â”†              â”† Programming with AI\",                              â”‚\n",
      "â”‚                              â”†              â”†   \"published\": \"Sun, 06 Oct 2024 18:47:46 +0000\",  â”‚\n",
      "â”‚                              â”†              â”† \"description\": \"Aman Sanger, Arvid Lunnemark,      â”‚\n",
      "â”‚                              â”†              â”† Michael Truell, and Sualeh Asif are creators of    â”‚\n",
      "â”‚                              â”†              â”† Cursor, a popular code editor that specializes in  â”‚\n",
      "â”‚                              â”†              â”† AI-assisted programming.<br />\\nThank you for      â”‚\n",
      "â”‚                              â”†              â”† listening â¤ Check out our sponsors:                â”‚\n",
      "â”‚                              â”†              â”† https://lexfridman.com/sponsors/ep447-sc<br        â”‚\n",
      "â”‚                              â”†              â”† />\\nSee below for timestamps, transcript, and to   â”‚\n",
      "â”‚                              â”†              â”† give feedback, submit questions, contact Lex,      â”‚\n",
      "â”‚                              â”†              â”† etc.<br />\\n<br />\\nTranscript:<br />\\nhttps://lex â”‚\n",
      "â”‚                              â”†              â”† fridman.com/cursor-team-transcript<br />\\n<br      â”‚\n",
      "â”‚                              â”†              â”† />\\nCONTACT LEX:<br />\\nFeedback - give feedback   â”‚\n",
      "â”‚                              â”†              â”† to Lex: https://lexfridman.com/survey<br />\\nAMA - â”‚\n",
      "â”‚                              â”†              â”† submit questions, videos or call-in:               â”‚\n",
      "â”‚                              â”†              â”† https://lexfridman.com/ama<br />\\nHiring - join    â”‚\n",
      "â”‚                              â”†              â”† our team: https://lexfridman.com/hiring<br         â”‚\n",
      "â”‚                              â”†              â”† />\\nOther - other ways to get in touch:            â”‚\n",
      "â”‚                              â”†              â”† https://lexfridman.com/contact<br />\\n<br          â”‚\n",
      "â”‚                              â”†              â”† />\\nEPISODE LINKS:<br />\\nCursor Website:          â”‚\n",
      "â”‚                              â”†              â”† https://cursor.com<br />\\nCursor on X:             â”‚\n",
      "â”‚                              â”†              â”† https://x.com/cursor_ai<br />\\â€¦                    â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "JSON cast to struct type:\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ file_name                    â”† metadata                                                          â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ lex_ai_cursor_team_meta.json â”† {\"#447 â€“ Cursor Team: Future of Programming with AI\",\"Sun, 06 Oct â”‚\n",
      "â”‚                              â”† 2024 18:47:46 +0000\",\"Aman Sanger, Arvid Lunnemark, Michael       â”‚\n",
      "â”‚                              â”† Truell, and Sualeh Asif are creators of Cursor, a popular code    â”‚\n",
      "â”‚                              â”† editor that specializes in AI-assisted programming.<br />         â”‚\n",
      "â”‚                              â”† Thank you for listening â¤ Check out our sponsors:                 â”‚\n",
      "â”‚                              â”† https://lexfridman.com/sponsors/ep447-sc<br />                    â”‚\n",
      "â”‚                              â”† See below for timestamps, transcript, and to give feedback,       â”‚\n",
      "â”‚                              â”† submit questions, contact Lex, etc.<br />                         â”‚\n",
      "â”‚                              â”† <br />                                                            â”‚\n",
      "â”‚                              â”† Transcript:<br />                                                 â”‚\n",
      "â”‚                              â”† https://lexfridman.com/cursor-team-transcript<br />               â”‚\n",
      "â”‚                              â”† <br />                                                            â”‚\n",
      "â”‚                              â”† CONTACT LEX:<br />                                                â”‚\n",
      "â”‚                              â”† Feedback - give feedback to Lex: https://lexfridman.com/survey<br â”‚\n",
      "â”‚                              â”† />                                                                â”‚\n",
      "â”‚                              â”† AMA - submit questions, videos or call-in:                        â”‚\n",
      "â”‚                              â”† https://lexfridman.com/ama<br />                                  â”‚\n",
      "â”‚                              â”† Hiring - join our team: https://lexfridman.com/hiring<br />       â”‚\n",
      "â”‚                              â”† Other - other ways to get in touch:                               â”‚\n",
      "â”‚                              â”† https://lexfridman.com/contact<br />                              â”‚\n",
      "â”‚                              â”† <br />                                                            â”‚\n",
      "â”‚                              â”† EPISODE LINKS:<br />                                              â”‚\n",
      "â”‚                              â”† Cursor Website: https://cursor.com<br />                          â”‚\n",
      "â”‚                              â”† Cursor on X: https://x.com/cursor_ai<br />                        â”‚\n",
      "â”‚                              â”† Anysphere Website: https://anysphere.inc/<br />                   â”‚\n",
      "â”‚                              â”† Aman's X: httâ€¦                                                    â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "Extracted metadata fields:\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ title                           â”† duration â”† description                    â”† description_length â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ #447 â€“ Cursor Team: Future of   â”† 2:37:38  â”† Aman Sanger, Arvid Lunnemark,  â”† 2885               â”‚\n",
      "â”‚ Programming with AI             â”†          â”† Michael Truell, and Sualeh     â”†                    â”‚\n",
      "â”‚                                 â”†          â”† Asif are creators of Cursor, a â”†                    â”‚\n",
      "â”‚                                 â”†          â”† popular code editor that       â”†                    â”‚\n",
      "â”‚                                 â”†          â”† specializes in AI-assisted     â”†                    â”‚\n",
      "â”‚                                 â”†          â”† programming.<br />             â”†                    â”‚\n",
      "â”‚                                 â”†          â”† Thank you for listening â¤      â”†                    â”‚\n",
      "â”‚                                 â”†          â”† Check out our sponsors: https: â”†                    â”‚\n",
      "â”‚                                 â”†          â”† //lexfridman.com/sponsors/ep44 â”†                    â”‚\n",
      "â”‚                                 â”†          â”† 7-sc<br />                     â”†                    â”‚\n",
      "â”‚                                 â”†          â”† See below for timestamps,      â”†                    â”‚\n",
      "â”‚                                 â”†          â”† transcript, and to give        â”†                    â”‚\n",
      "â”‚                                 â”†          â”† feedback, submit questions,    â”†                    â”‚\n",
      "â”‚                                 â”†          â”† contact Lex, etc.<br />        â”†                    â”‚\n",
      "â”‚                                 â”†          â”† <br />                         â”†                    â”‚\n",
      "â”‚                                 â”†          â”† Transcript:<br />              â”†                    â”‚\n",
      "â”‚                                 â”†          â”† https://lexfridman.com/cursor- â”†                    â”‚\n",
      "â”‚                                 â”†          â”† team-transcript<br />          â”†                    â”‚\n",
      "â”‚                                 â”†          â”† <br />                         â”†                    â”‚\n",
      "â”‚                                 â”†          â”† CONTACT LEX:<br />             â”†                    â”‚\n",
      "â”‚                                 â”†          â”† Feedback - give feedback to    â”†                    â”‚\n",
      "â”‚                                 â”†          â”† Lex: https://lexfridman.com/su â”†                    â”‚\n",
      "â”‚                                 â”†          â”† rvey<br />                     â”†                    â”‚\n",
      "â”‚                                 â”†          â”† AMA - submit questions, videos â”†                    â”‚\n",
      "â”‚                                 â”†          â”† or call-in:                    â”†                    â”‚\n",
      "â”‚                                 â”†          â”† https://lexfridman.com/ama<br  â”†                    â”‚\n",
      "â”‚                                 â”†          â”† />                             â”†                    â”‚\n",
      "â”‚                                 â”†          â”† Hiring - join our team: https: â”†                    â”‚\n",
      "â”‚                                 â”†          â”† //lexfridman.com/hiring<br />  â”†                    â”‚\n",
      "â”‚                                 â”†          â”† Other - other ways to get in   â”†                    â”‚\n",
      "â”‚                                 â”†          â”† touch: https://lexfridman.com/ â”†                    â”‚\n",
      "â”‚                                 â”†          â”† contact<br />                  â”†                    â”‚\n",
      "â”‚                                 â”†          â”† <br />                         â”†                    â”‚\n",
      "â”‚                                 â”†          â”† EPISODE LINKS:<br />           â”†                    â”‚\n",
      "â”‚                                 â”†          â”† Cursor Website:                â”†                    â”‚\n",
      "â”‚                                 â”†          â”† https://cursor.com<br />       â”†                    â”‚\n",
      "â”‚                                 â”†          â”† Cursor on X:                   â”†                    â”‚\n",
      "â”‚                                 â”†          â”† https://x.com/cursor_ai<br />  â”†                    â”‚\n",
      "â”‚                                 â”†          â”† Anysphere Website:             â”†                    â”‚\n",
      "â”‚                                 â”†          â”† https://anysphere.inc/<br />   â”†                    â”‚\n",
      "â”‚                                 â”†          â”† Aman's X:                      â”†                    â”‚\n",
      "â”‚                                 â”†          â”† https://x.com/amanrsanger<br   â”†                    â”‚\n",
      "â”‚                                 â”†          â”† />                             â”†                    â”‚\n",
      "â”‚                                 â”†          â”† Aman's Website:                â”†                    â”‚\n",
      "â”‚                                 â”†          â”† https://amansanger.com/<br />  â”†                    â”‚\n",
      "â”‚                                 â”†          â”† Arvid's X: htâ€¦                 â”†                    â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "Metadata processing complete - ready for summarization!\n"
     ]
    }
   ],
   "source": [
    "# 4. Process metadata: Convert string to JSON type and extract fields\n",
    "print(\"\\n=== Step 4: Processing Metadata ===\")\n",
    "\n",
    "# Cast content string to JSON type\n",
    "meta_json_df = meta_df.select(\n",
    "    fc.col(\"file_name\"),\n",
    "    fc.col(\"content_type\"),\n",
    "    fc.col(\"content\").cast(fc.JsonType).alias(\"json_data\")\n",
    ")\n",
    "\n",
    "print(\"Metadata converted to JSON type:\")\n",
    "meta_json_df.show(1)\n",
    "\n",
    "# Define metadata struct type\n",
    "metadata_struct = fc.StructType([\n",
    "    fc.StructField(\"title\", fc.StringType),\n",
    "    fc.StructField(\"published\", fc.StringType),\n",
    "    fc.StructField(\"description\", fc.StringType),\n",
    "    fc.StructField(\"duration\", fc.StringType),\n",
    "    fc.StructField(\"audio_url\", fc.StringType),\n",
    "    fc.StructField(\"link\", fc.StringType)\n",
    "])\n",
    "\n",
    "# Cast entire JSON blob to struct\n",
    "meta_struct_df = meta_json_df.select(\n",
    "    fc.col(\"file_name\"),\n",
    "    fc.col(\"json_data\").cast(metadata_struct).alias(\"metadata\")\n",
    ")\n",
    "\n",
    "print(\"JSON cast to struct type:\")\n",
    "meta_struct_df.show(1)\n",
    "\n",
    "# Extract fields from struct\n",
    "meta_extracted_df = meta_struct_df.select(\n",
    "    fc.col(\"file_name\"),\n",
    "    fc.col(\"metadata\").title.alias(\"title\"),\n",
    "    fc.col(\"metadata\").published.alias(\"published\"),\n",
    "    fc.col(\"metadata\").description.alias(\"description\"),\n",
    "    fc.col(\"metadata\").duration.alias(\"duration\"),\n",
    "    fc.col(\"metadata\").audio_url.alias(\"audio_url\"),\n",
    "    fc.col(\"metadata\").link.alias(\"link\")\n",
    ")\n",
    "\n",
    "print(\"\\nExtracted metadata fields:\")\n",
    "meta_extracted_df.select(\n",
    "    fc.col(\"title\"),\n",
    "    fc.col(\"duration\"),\n",
    "    fc.col(\"description\"),\n",
    "    fc.text.length(fc.col(\"description\")).alias(\"description_length\")\n",
    ").show()\n",
    "\n",
    "print(\"\\nMetadata processing complete - ready for summarization!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 5: Creating Word-Level DataFrame ===\n",
      "Transcript converted to JSON type:\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ file_name               â”† content_type â”† json_data                                           â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ lex_ai_cursor_team.json â”† transcript   â”† {                                                   â”‚\n",
      "â”‚                         â”†              â”†   \"segments\": [                                     â”‚\n",
      "â”‚                         â”†              â”†     {                                               â”‚\n",
      "â”‚                         â”†              â”†       \"start\": 0.031,                               â”‚\n",
      "â”‚                         â”†              â”†       \"end\": 9.66,                                  â”‚\n",
      "â”‚                         â”†              â”† \"text\": \" The following is a conversation with the  â”‚\n",
      "â”‚                         â”†              â”† founding members of the Cursor team, Michael Truel, â”‚\n",
      "â”‚                         â”†              â”† Swale Asif, Arvid Lundmark, and Aman Sanger.\",      â”‚\n",
      "â”‚                         â”†              â”†       \"words\": [                                    â”‚\n",
      "â”‚                         â”†              â”†         {                                           â”‚\n",
      "â”‚                         â”†              â”†           \"word\": \"The\",                            â”‚\n",
      "â”‚                         â”†              â”†           \"start\": 0.031,                           â”‚\n",
      "â”‚                         â”†              â”†           \"end\": 0.211,                             â”‚\n",
      "â”‚                         â”†              â”†           \"score\": 0.922,                           â”‚\n",
      "â”‚                         â”†              â”†           \"speaker\": \"SPEAKER_05\"                   â”‚\n",
      "â”‚                         â”†              â”†         },                                          â”‚\n",
      "â”‚                         â”†              â”†         {                                           â”‚\n",
      "â”‚                         â”†              â”†           \"word\": \"following\",                      â”‚\n",
      "â”‚                         â”†              â”†           \"start\": 0.251,                           â”‚\n",
      "â”‚                         â”†              â”†           \"end\": 0.632,                             â”‚\n",
      "â”‚                         â”†              â”†           \"score\": 0.782,                           â”‚\n",
      "â”‚                         â”†              â”†           \"speaker\": \"SPEAKER_05\"                   â”‚\n",
      "â”‚                         â”†              â”†         },                                          â”‚\n",
      "â”‚                         â”†              â”†         {                                           â”‚\n",
      "â”‚                         â”†              â”†           \"word\": \"is\",                             â”‚\n",
      "â”‚                         â”†              â”†           \"start\": 0.652,                           â”‚\n",
      "â”‚                         â”†              â”†           \"end\": 0.772,                             â”‚\n",
      "â”‚                         â”†              â”†           \"score\": 0.501,                           â”‚\n",
      "â”‚                         â”†              â”†           \"speaker\": \"SPEAKER_05\"                   â”‚\n",
      "â”‚                         â”†              â”†         },                                          â”‚\n",
      "â”‚                         â”†              â”†         {                                           â”‚\n",
      "â”‚                         â”†              â”†           \"word\": \"a\",                              â”‚\n",
      "â”‚                         â”†              â”†           \"start\": 0.792,                           â”‚\n",
      "â”‚                         â”†              â”†           \"end\": 0.812,                             â”‚\n",
      "â”‚                         â”†              â”†           \"score\": 0.999,                           â”‚\n",
      "â”‚                         â”†              â”†           \"speaker\": \"SPEAKER_05\"                   â”‚\n",
      "â”‚                         â”†              â”†         },                                          â”‚\n",
      "â”‚                         â”†              â”†         {                                           â”‚\n",
      "â”‚                         â”†              â”†           \"word\": \"conversation\",                   â”‚\n",
      "â”‚                         â”†              â”†           \"start\": 0.852,                           â”‚\n",
      "â”‚                         â”†              â”†           \"end\": 1.452,                             â”‚\n",
      "â”‚                         â”†              â”†           \"score\": 0.809,                           â”‚\n",
      "â”‚                         â”†              â”†           \"speaâ€¦                                    â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "Extracted word objects: 27761 words\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ word_data                                                                            â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ {\"end\":0.211,\"score\":0.922,\"speaker\":\"SPEAKER_05\",\"start\":0.031,\"word\":\"The\"}        â”‚\n",
      "â”‚ {\"end\":0.632,\"score\":0.782,\"speaker\":\"SPEAKER_05\",\"start\":0.251,\"word\":\"following\"}  â”‚\n",
      "â”‚ â€¦                                                                                    â”‚\n",
      "â”‚ {\"end\":9441.546,\"score\":0.84,\"speaker\":\"SPEAKER_05\",\"start\":9441.266,\"word\":\"time.\"} â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "ğŸ“Š Word-Level DataFrame with calculated fields:\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ word_text    â”† speaker    â”† start_time  â”† end_time    â”† confidence_score â”† duration â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ The          â”† SPEAKER_05 â”† 0.031       â”† 0.211       â”† 0.922            â”† 0.18     â”‚\n",
      "â”‚ following    â”† SPEAKER_05 â”† 0.251       â”† 0.632       â”† 0.782            â”† 0.381    â”‚\n",
      "â”‚ is           â”† SPEAKER_05 â”† 0.652       â”† 0.772       â”† 0.501            â”† 0.12     â”‚\n",
      "â”‚ a            â”† SPEAKER_05 â”† 0.792       â”† 0.812       â”† 0.999            â”† 0.02     â”‚\n",
      "â”‚ conversation â”† SPEAKER_05 â”† 0.852       â”† 1.452       â”† 0.809            â”† 0.6      â”‚\n",
      "â”‚ â€¦            â”† â€¦          â”† â€¦           â”† â€¦           â”† â€¦                â”† â€¦        â”‚\n",
      "â”‚ to           â”† SPEAKER_05 â”† 9440.06543  â”† 9440.144531 â”† 0.687            â”† 0.079102 â”‚\n",
      "â”‚ see          â”† SPEAKER_05 â”† 9440.165039 â”† 9440.285156 â”† 0.964            â”† 0.120117 â”‚\n",
      "â”‚ you          â”† SPEAKER_05 â”† 9440.304688 â”† 9440.384766 â”† 0.83             â”† 0.080078 â”‚\n",
      "â”‚ next         â”† SPEAKER_05 â”† 9440.445312 â”† 9441.225586 â”† 0.847            â”† 0.780273 â”‚\n",
      "â”‚ time.        â”† SPEAKER_05 â”† 9441.265625 â”† 9441.545898 â”† 0.84             â”† 0.280273 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "Word-level extraction complete: 27761 words processed\n"
     ]
    }
   ],
   "source": [
    "# 5. Process transcript: Create word-level DataFrame\n",
    "print(\"\\n=== Step 5: Creating Word-Level DataFrame ===\")\n",
    "\n",
    "# Cast transcript content to JSON type\n",
    "transcript_json_df = transcript_df.select(\n",
    "    fc.col(\"file_name\"),\n",
    "    fc.col(\"content_type\"),\n",
    "    fc.col(\"content\").cast(fc.JsonType).alias(\"json_data\")\n",
    ")\n",
    "\n",
    "print(\"Transcript converted to JSON type:\")\n",
    "transcript_json_df.show(1)\n",
    "\n",
    "# Extract all words from all segments using simplified JQ\n",
    "words_raw_df = transcript_json_df.select(\n",
    "    fc.json.jq(\n",
    "        fc.col(\"json_data\"),\n",
    "        # Much simpler: just get all words from all segments\n",
    "        '.segments[] | .words[]'\n",
    "    ).alias(\"word_data\")\n",
    ").explode(\"word_data\")  # Convert array of word objects into separate rows\n",
    "\n",
    "print(f\"Extracted word objects: {words_raw_df.count()} words\")\n",
    "words_raw_df.show(3)\n",
    "\n",
    "# Extract and cast individual word fields to proper types\n",
    "words_df = words_raw_df.select(\n",
    "    # Extract basic word-level fields only\n",
    "    fc.json.jq(fc.col(\"word_data\"), '.word').get_item(0).cast(fc.StringType).alias(\"word_text\"),\n",
    "    fc.json.jq(fc.col(\"word_data\"), '.speaker').get_item(0).cast(fc.StringType).alias(\"speaker\"),\n",
    "    fc.json.jq(fc.col(\"word_data\"), '.start').get_item(0).cast(fc.FloatType).alias(\"start_time\"),\n",
    "    fc.json.jq(fc.col(\"word_data\"), '.end').get_item(0).cast(fc.FloatType).alias(\"end_time\"),\n",
    "    fc.json.jq(fc.col(\"word_data\"), '.score').get_item(0).cast(fc.FloatType).alias(\"confidence_score\")\n",
    ").select(\n",
    "    # Add calculated fields\n",
    "    \"*\",\n",
    "    (fc.col(\"end_time\") - fc.col(\"start_time\")).alias(\"duration\")\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ“Š Word-Level DataFrame with calculated fields:\")\n",
    "words_df.show(10)\n",
    "\n",
    "print(f\"\\nWord-level extraction complete: {words_df.count()} words processed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 6: Creating Segment-Level DataFrame ===\n",
      "Extracted segment objects: 1786 segments\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ segment_data                                                                                     â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ {\"end\":9.66,\"speaker\":\"SPEAKER_05\",\"start\":0.031,\"text\":\" The following is a conversation with   â”‚\n",
      "â”‚ the founding members of the Cursor team, Michael Truel, Swale Asif, Arvid Lundmark, and Aman San â”‚\n",
      "â”‚ ger.\",\"words\":[{\"end\":0.211,\"score\":0.922,\"speaker\":\"SPEAKER_05\",\"start\":0.031,\"word\":\"The\"},{\"e â”‚\n",
      "â”‚ nd\":0.632,\"score\":0.782,\"speaker\":\"SPEAKER_05\",\"start\":0.251,\"word\":\"following\"},{\"end\":0.772,\"s â”‚\n",
      "â”‚ core\":0.501,\"speaker\":\"SPEAKER_05\",\"start\":0.652,\"word\":\"is\"},{\"end\":0.812,\"score\":0.999,\"speake â”‚\n",
      "â”‚ r\":\"SPEAKER_05\",\"start\":0.792,\"word\":\"a\"},{\"end\":1.452,\"score\":0.809,\"speaker\":\"SPEAKER_05\",\"sta â”‚\n",
      "â”‚ rt\":0.852,\"word\":\"conversation\"},{\"end\":2.073,\"score\":0.936,\"speaker\":\"SPEAKER_05\",\"start\":1.913 â”‚\n",
      "â”‚ ,\"word\":\"with\"},{\"end\":2.273,\"score\":0.775,\"speaker\":\"SPEAKER_05\",\"start\":2.153,\"word\":\"the\"},{\" â”‚\n",
      "â”‚ end\":2.773,\"score\":0.947,\"speaker\":\"SPEAKER_05\",\"start\":2.413,\"word\":\"founding\"},{\"end\":3.154,\"s â”‚\n",
      "â”‚ core\":0.816,\"speaker\":\"SPEAKER_05\",\"start\":2.854,\"word\":\"members\"},{\"end\":3.274,\"score\":0.75,\"sp â”‚\n",
      "â”‚ eaker\":\"SPEAKER_05\",\"start\":3.214,\"word\":â€¦                                                       â”‚\n",
      "â”‚ {\"end\":17.387,\"speaker\":\"SPEAKER_05\",\"start\":10.48,\"text\":\"Cursor is a code editor based on VS   â”‚\n",
      "â”‚ Code that adds a lot of powerful features for AI-assisted coding.\",\"words\":[{\"end\":10.881,\"score â”‚\n",
      "â”‚ \":0.849,\"speaker\":\"SPEAKER_05\",\"start\":10.48,\"word\":\"Cursor\"},{\"end\":11.341,\"score\":0.968,\"speak â”‚\n",
      "â”‚ er\":\"SPEAKER_05\",\"start\":11.261,\"word\":\"is\"},{\"end\":11.541,\"score\":0.754,\"speaker\":\"SPEAKER_05\", â”‚\n",
      "â”‚ \"start\":11.381,\"word\":\"a\"},{\"end\":11.822,\"score\":0.679,\"speaker\":\"SPEAKER_05\",\"start\":11.622,\"wo â”‚\n",
      "â”‚ rd\":\"code\"},{\"end\":12.162,\"score\":0.939,\"speaker\":\"SPEAKER_05\",\"start\":11.862,\"word\":\"editor\"},{ â”‚\n",
      "â”‚ \"end\":13.003,\"score\":0.9,\"speaker\":\"SPEAKER_05\",\"start\":12.723,\"word\":\"based\"},{\"end\":13.223,\"sc â”‚\n",
      "â”‚ ore\":0.774,\"speaker\":\"SPEAKER_05\",\"start\":13.143,\"word\":\"on\"},{\"end\":13.563,\"score\":0.845,\"speak â”‚\n",
      "â”‚ er\":\"SPEAKER_05\",\"start\":13.283,\"word\":\"VS\"},{\"end\":13.884,\"score\":0.951,\"speaker\":\"SPEAKER_05\", â”‚\n",
      "â”‚ \"start\":13.603,\"word\":\"Code\"},{\"end\":14.504,\"score\":0.993,\"speaker\":\"SPEAKER_05\",\"start\":14.364, â”‚\n",
      "â”‚ \"word\":\"that\"},{\"end\":14.744,\"score\":0.66â€¦                                                       â”‚\n",
      "â”‚ â€¦                                                                                                â”‚\n",
      "â”‚ {\"end\":9441.546,\"speaker\":\"SPEAKER_05\",\"start\":9438.703,\"text\":\"Thank you for listening, and     â”‚\n",
      "â”‚ hope to see you next time.\",\"words\":[{\"end\":9438.823,\"score\":0.991,\"speaker\":\"SPEAKER_05\",\"start â”‚\n",
      "â”‚ \":9438.703,\"word\":\"Thank\"},{\"end\":9438.923,\"score\":0.78,\"speaker\":\"SPEAKER_05\",\"start\":9438.843, â”‚\n",
      "â”‚ \"word\":\"you\"},{\"end\":9439.024,\"score\":0.795,\"speaker\":\"SPEAKER_05\",\"start\":9438.943,\"word\":\"for\" â”‚\n",
      "â”‚ },{\"end\":9439.364,\"score\":0.882,\"speaker\":\"SPEAKER_05\",\"start\":9439.044,\"word\":\"listening,\"},{\"e â”‚\n",
      "â”‚ nd\":9439.884,\"score\":0.685,\"speaker\":\"SPEAKER_05\",\"start\":9439.824,\"word\":\"and\"},{\"end\":9440.045 â”‚\n",
      "â”‚ ,\"score\":0.908,\"speaker\":\"SPEAKER_05\",\"start\":9439.944,\"word\":\"hope\"},{\"end\":9440.145,\"score\":0. â”‚\n",
      "â”‚ 687,\"speaker\":\"SPEAKER_05\",\"start\":9440.065,\"word\":\"to\"},{\"end\":9440.285,\"score\":0.964,\"speaker\" â”‚\n",
      "â”‚ :\"SPEAKER_05\",\"start\":9440.165,\"word\":\"see\"},{\"end\":9440.385,\"score\":0.83,\"speaker\":\"SPEAKER_05\" â”‚\n",
      "â”‚ ,\"start\":9440.305,\"word\":\"you\"},{\"end\":9441.226,\"score\":0.847,\"speaker\":\"SPEAKER_05\",\"start\":944 â”‚\n",
      "â”‚ 0.445,\"word\":\"next\"},{\"end\":9441.546,\"scoreâ€¦                                                     â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "ğŸ“Š Segment-Level DataFrame with calculated metrics:\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ segment_text   â”† start_time  â”† end_time    â”† speaker    â”† word_count â”† average_confi â”† duration  â”‚\n",
      "â”‚                â”†             â”†             â”†            â”†            â”† dence         â”†           â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ The following  â”† 0.031       â”† 9.66        â”† SPEAKER_05 â”† 22         â”† 0.827727      â”† 9.629     â”‚\n",
      "â”‚ is a           â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ conversation   â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ with the       â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ founding       â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ members of the â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ Cursor team,   â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ Michael Truel, â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ Swale Asif,    â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ Arvid          â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ Lundmark, and  â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ Aman Sanger.   â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ Cursor is a    â”† 10.48       â”† 17.386999   â”† SPEAKER_05 â”† 19         â”† 0.816895      â”† 6.907     â”‚\n",
      "â”‚ code editor    â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ based on VS    â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ Code that adds â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ a lot of       â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ powerful       â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ features for   â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ AI-assisted    â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ coding.        â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ It has         â”† 18.127001   â”† 23.172001   â”† SPEAKER_05 â”† 13         â”† 0.805231      â”† 5.045     â”‚\n",
      "â”‚ captivated the â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ attention and  â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ excitement of  â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ the            â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ programming    â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ and AI         â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ communities.   â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ â€¦              â”† â€¦           â”† â€¦           â”† â€¦          â”† â€¦          â”† â€¦             â”† â€¦         â”‚\n",
      "â”‚ Nothing is as  â”† 9432.958008 â”† 9437.12207  â”† SPEAKER_05 â”† 10         â”† 0.8982        â”† 4.1640625 â”‚\n",
      "â”‚ permanent as a â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ temporary      â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ solution that  â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ works.         â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ Thank you for  â”† 9438.703125 â”† 9441.545898 â”† SPEAKER_05 â”† 11         â”† 0.837182      â”† 2.842773  â”‚\n",
      "â”‚ listening, and â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ hope to see    â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â”‚ you next time. â”†             â”†             â”†            â”†            â”†               â”†           â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "Segment-level extraction complete: 1786 segments processed\n"
     ]
    }
   ],
   "source": [
    "# 6. Process transcript: Create segment-level DataFrame\n",
    "print(\"\\n=== Step 6: Creating Segment-Level DataFrame ===\")\n",
    "\n",
    "# Extract segments using JQ\n",
    "segments_raw_df = transcript_json_df.select(\n",
    "    fc.json.jq(\n",
    "        fc.col(\"json_data\"),\n",
    "        # Extract segment objects with their text, timing, and word arrays\n",
    "        '.segments[]'\n",
    "    ).alias(\"segment_data\")\n",
    ").explode(\"segment_data\")  # Convert segments array into separate rows\n",
    "\n",
    "print(f\"Extracted segment objects: {segments_raw_df.count()} segments\")\n",
    "segments_raw_df.show(3)\n",
    "\n",
    "# Extract segment fields and calculate aggregated metrics\n",
    "segments_df = segments_raw_df.select(\n",
    "    # Extract basic segment data\n",
    "    fc.json.jq(fc.col(\"segment_data\"), '.text').get_item(0).cast(fc.StringType).alias(\"segment_text\"),\n",
    "    fc.json.jq(fc.col(\"segment_data\"), '.start').get_item(0).cast(fc.FloatType).alias(\"start_time\"),\n",
    "    fc.json.jq(fc.col(\"segment_data\"), '.end').get_item(0).cast(fc.FloatType).alias(\"end_time\"),\n",
    "    # Extract speaker directly from segment\n",
    "    fc.json.jq(fc.col(\"segment_data\"), '.speaker').get_item(0).cast(fc.StringType).alias(\"speaker\"),\n",
    "    # Calculate word count using JQ array length\n",
    "    fc.json.jq(fc.col(\"segment_data\"), '.words | length').get_item(0).cast(fc.IntegerType).alias(\"word_count\"),\n",
    "    # Calculate average confidence using JQ array aggregation\n",
    "    fc.json.jq(fc.col(\"segment_data\"), '[.words[].score] | add / length').get_item(0).cast(fc.FloatType).alias(\"average_confidence\")\n",
    ").select(\n",
    "    # Add calculated fields\n",
    "    \"*\",\n",
    "    (fc.col(\"end_time\") - fc.col(\"start_time\")).alias(\"duration\")\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ“Š Segment-Level DataFrame with calculated metrics:\")\n",
    "segments_df.show(5)\n",
    "\n",
    "print(f\"\\nSegment-level extraction complete: {segments_df.count()} segments processed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 7: Extracting Host and Guest Names ===\n",
      "Semantic extraction of speakers applied\n",
      "\n",
      "ğŸ“Š Extracted Speaker Information:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Submitting requests for batch: 1389d072-2324-4ef7-9754-64e990704edf: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 432.36req/s, estimated_input_tokens=1015, estimated_output_tokens=1024]\n",
      "Awaiting responses for batch 1389d072-2324-4ef7-9754-64e990704edf (model: gpt-4o-mini): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.86s/res]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ title                  â”† duration â”† host_name   â”† guest_names            â”† guest_roles           â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ #447 â€“ Cursor Team:    â”† 2:37:38  â”† Lex Fridman â”† [\"Aman Sanger\", \"Arvid â”† [\"Creators of Cursor, â”‚\n",
      "â”‚ Future of Programming  â”†          â”†             â”† Lunnemark\", â€¦ \"Sualeh  â”† a popular code editor â”‚\n",
      "â”‚ with AI                â”†          â”†             â”† Asif\"]                 â”† specializing in       â”‚\n",
      "â”‚                        â”†          â”†             â”†                        â”† AI-assisted           â”‚\n",
      "â”‚                        â”†          â”†             â”†                        â”† programming\"]         â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "Speaker extraction complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. Extract host and guest names using semantic operations\n",
    "print(\"\\n=== Step 7: Extracting Host and Guest Names ===\")\n",
    "\n",
    "# Define schema for extracting speaker information\n",
    "podcast_speakers_schema = fc.ExtractSchema([\n",
    "    # Single host name\n",
    "    fc.ExtractSchemaField(\n",
    "        name=\"host_name\",\n",
    "        data_type=fc.StringType,\n",
    "        description=\"The name of the podcast host (usually Lex Fridman)\"\n",
    "    ),\n",
    "    # List of guest names\n",
    "    fc.ExtractSchemaField(\n",
    "        name=\"guest_names\",\n",
    "        data_type=fc.ExtractSchemaList(element_type=fc.StringType),\n",
    "        description=\"List of all guest names mentioned in the podcast description\"\n",
    "    ),\n",
    "    # List of guest roles/titles\n",
    "    fc.ExtractSchemaField(\n",
    "        name=\"guest_roles\",\n",
    "        data_type=fc.ExtractSchemaList(element_type=fc.StringType),\n",
    "        description=\"List of professional roles, titles, or affiliations of the guests\"\n",
    "    )\n",
    "])\n",
    "\n",
    "# Apply semantic extraction to the description field\n",
    "speakers_extracted_df = meta_extracted_df.select(\n",
    "    \"*\",\n",
    "    fc.semantic.extract(fc.col(\"description\"), podcast_speakers_schema).alias(\"speakers_info\")\n",
    ")\n",
    "\n",
    "print(\"Semantic extraction of speakers applied\")\n",
    "\n",
    "# Extract speaker information into clean columns\n",
    "speakers_df = speakers_extracted_df.select(\n",
    "    fc.col(\"title\"),\n",
    "    fc.col(\"duration\"),\n",
    "    speakers_extracted_df.speakers_info.host_name.alias(\"host_name\"),\n",
    "    speakers_extracted_df.speakers_info.guest_names.alias(\"guest_names\"),\n",
    "    speakers_extracted_df.speakers_info.guest_roles.alias(\"guest_roles\")\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ“Š Extracted Speaker Information:\")\n",
    "speakers_df.show()\n",
    "\n",
    "print(\"\\nSpeaker extraction complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 8: Identifying Speaker Names ===\n",
      "Aggregated speech by speaker:\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ speaker    â”† first_speaking_time â”† segment_count â”† total_speaking_time â”† speech_length â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ SPEAKER_05 â”† 0.031               â”† 505           â”† 1903.593506         â”† 32861         â”‚\n",
      "â”‚ SPEAKER_02 â”† 576.609985          â”† 223           â”† 1134.180176         â”† 22383         â”‚\n",
      "â”‚ SPEAKER_03 â”† 645.937988          â”† 299           â”† 1439.050781         â”† 24412         â”‚\n",
      "â”‚ SPEAKER_01 â”† 719.591003          â”† 455           â”† 2743.926025         â”† 47644         â”‚\n",
      "â”‚ SPEAKER_04 â”† 726.359985          â”† 295           â”† 1441.587646         â”† 24387         â”‚\n",
      "â”‚ null       â”† 2053.783936         â”† 8             â”† 0.920898            â”† 48            â”‚\n",
      "â”‚ SPEAKER_00 â”† 8306.250977         â”† 1             â”† 0.219727            â”† 5             â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "Filtered out speakers with < 60 seconds of speech\n",
      "Remaining speakers:\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ speaker    â”† first_speaking_time â”† total_speaking_time â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ SPEAKER_05 â”† 0.031               â”† 1903.593506         â”‚\n",
      "â”‚ SPEAKER_02 â”† 576.609985          â”† 1134.180176         â”‚\n",
      "â”‚ SPEAKER_03 â”† 645.937988          â”† 1439.050781         â”‚\n",
      "â”‚ SPEAKER_01 â”† 719.591003          â”† 2743.926025         â”‚\n",
      "â”‚ SPEAKER_04 â”† 726.359985          â”† 1441.587646         â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "Applying manual speaker mapping...\n",
      "\n",
      "ğŸ“Š Speaker Identification Results:\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ speaker    â”† first_speaking_time â”† total_speaking_time â”† identified_name â”† role  â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•¡\n",
      "â”‚ SPEAKER_05 â”† 0.031               â”† 1903.593506         â”† Lex Fridman     â”† HOST  â”‚\n",
      "â”‚ SPEAKER_02 â”† 576.609985          â”† 1134.180176         â”† Michael Truell  â”† GUEST â”‚\n",
      "â”‚ SPEAKER_03 â”† 645.937988          â”† 1439.050781         â”† Arvid Lunnemark â”† GUEST â”‚\n",
      "â”‚ SPEAKER_01 â”† 719.591003          â”† 2743.926025         â”† Aman Sanger     â”† GUEST â”‚\n",
      "â”‚ SPEAKER_04 â”† 726.359985          â”† 1441.587646         â”† Sualeh Asif     â”† GUEST â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "Speaker identification complete!\n"
     ]
    }
   ],
   "source": [
    "# 8. Identify speakers by analyzing their speech patterns\n",
    "print(\"\\n=== Step 8: Identifying Speaker Names ===\")\n",
    "\n",
    "# Aggregate all speech by speaker\n",
    "speaker_aggregated_df = segments_df.group_by(\"speaker\").agg(\n",
    "    fc.collect_list(\"segment_text\").alias(\"speech_segments\"),\n",
    "    fc.min(\"start_time\").alias(\"first_speaking_time\"),\n",
    "    fc.max(\"end_time\").alias(\"last_speaking_time\"),\n",
    "    fc.count(\"*\").alias(\"segment_count\"),\n",
    "    fc.sum(\"duration\").alias(\"total_speaking_time\")\n",
    ").select(\n",
    "    \"*\",\n",
    "    fc.text.array_join(fc.col(\"speech_segments\"), \" \").alias(\"full_speech\")\n",
    ")\n",
    "\n",
    "print(\"Aggregated speech by speaker:\")\n",
    "speaker_aggregated_df.select(\n",
    "    fc.col(\"speaker\"),\n",
    "    fc.col(\"first_speaking_time\"),\n",
    "    fc.col(\"segment_count\"),\n",
    "    fc.col(\"total_speaking_time\"),\n",
    "    fc.text.length(fc.col(\"full_speech\")).alias(\"speech_length\")\n",
    ").sort(\"first_speaking_time\").show()\n",
    "\n",
    "# Filter out speakers with minimal speaking time (< 60 seconds) to remove ads/noise\n",
    "speaker_filtered_df = speaker_aggregated_df.filter(\n",
    "    fc.col(\"total_speaking_time\") >= 60.0  # At least 1 minute of speaking\n",
    ")\n",
    "\n",
    "print(\"\\nFiltered out speakers with < 60 seconds of speech\")\n",
    "print(\"Remaining speakers:\")\n",
    "speaker_filtered_df.select(\n",
    "    fc.col(\"speaker\"),\n",
    "    fc.col(\"first_speaking_time\"),\n",
    "    fc.col(\"total_speaking_time\")\n",
    ").sort(\"first_speaking_time\").show()\n",
    "\n",
    "# Sort by first speaking time to see who spoke first\n",
    "speaker_sorted_df = speaker_filtered_df.sort(\"first_speaking_time\")\n",
    "\n",
    "print(\"\\nApplying manual speaker mapping...\")\n",
    "\n",
    "# Create speaker mapping based on provided assignments\n",
    "speaker_mapping_df = speaker_sorted_df.select(\n",
    "    fc.col(\"speaker\"),\n",
    "    fc.col(\"first_speaking_time\"),\n",
    "    fc.col(\"total_speaking_time\"),\n",
    "    # Map speakers to actual names\n",
    "    fc.when(fc.col(\"speaker\") == \"SPEAKER_05\", fc.lit(\"Lex Fridman\"))\n",
    "    .when(fc.col(\"speaker\") == \"SPEAKER_02\", fc.lit(\"Michael Truell\"))\n",
    "    .when(fc.col(\"speaker\") == \"SPEAKER_03\", fc.lit(\"Arvid Lunnemark\"))\n",
    "    .when(fc.col(\"speaker\") == \"SPEAKER_01\", fc.lit(\"Aman Sanger\"))\n",
    "    .when(fc.col(\"speaker\") == \"SPEAKER_04\", fc.lit(\"Sualeh Asif\"))\n",
    "    .otherwise(fc.lit(\"Unknown\")).alias(\"identified_name\"),\n",
    "    # Map speakers to roles\n",
    "    fc.when(fc.col(\"speaker\") == \"SPEAKER_05\", fc.lit(\"HOST\"))\n",
    "    .otherwise(fc.lit(\"GUEST\")).alias(\"role\")\n",
    ").sort(\"first_speaking_time\")\n",
    "\n",
    "print(\"\\nğŸ“Š Speaker Identification Results:\")\n",
    "speaker_mapping_df.show()\n",
    "\n",
    "print(\"\\nSpeaker identification complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 9: Chunked Recursive Summarization ===\n",
      "Full transcript assembled\n",
      "Transcript split into 22 chunks\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ chunk_length â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 7737         â”‚\n",
      "â”‚ 7488         â”‚\n",
      "â”‚ 7621         â”‚\n",
      "â”‚ â€¦            â”‚\n",
      "â”‚ 7415         â”‚\n",
      "â”‚ 5652         â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "Step 2: Summarizing individual chunks...\n",
      "Individual chunk summaries created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Submitting requests for batch: db2b246d-dce4-497b-923a-5dcc7f78d745: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 497.15req/s, estimated_input_tokens=39803, estimated_output_tokens=11264]\n",
      "Awaiting responses for batch db2b246d-dce4-497b-923a-5dcc7f78d745 (model: gpt-4o-mini): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:07<00:00,  2.93res/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ summary_length â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 669            â”‚\n",
      "â”‚ 1421           â”‚\n",
      "â”‚ 1551           â”‚\n",
      "â”‚ â€¦              â”‚\n",
      "â”‚ 1575           â”‚\n",
      "â”‚ 1177           â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "Step 3: Recursive combination of summaries...\n",
      "\n",
      "ğŸ“‹ Final Podcast Summary:\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Submitting requests for batch: aaff7bd9-513a-4774-9083-25bd4045284a: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<00:00, 566.74req/s, estimated_input_tokens=39803, estimated_output_tokens=11264]\n",
      "Awaiting responses for batch aaff7bd9-513a-4774-9083-25bd4045284a (model: gpt-4o-mini): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:09<00:00,  2.24res/s]\n",
      "Submitting requests for batch: 153fcecb-acc4-481a-89db-6a2213330df8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 135.56req/s, estimated_input_tokens=5866, estimated_output_tokens=512]\n",
      "Awaiting responses for batch 153fcecb-acc4-481a-89db-6a2213330df8 (model: gpt-4o-mini): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:07<00:00,  7.98s/res]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ final_summary                                                                                    â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ The Lex Fridman podcast episode featuring the Cursor teamâ€”Michael Truel, Sualeh Asif, Arvid      â”‚\n",
      "â”‚ Lundmark, and Aman Sangerâ€”delves into the transformative potential of AI in programming,         â”‚\n",
      "â”‚ particularly through their innovative AI-assisted code editor built on VS Code. The conversation â”‚\n",
      "â”‚ encapsulates key themes such as the evolution of code editors, the integration of AI in software â”‚\n",
      "â”‚ development, and the future of human-AI collaboration.                                           â”‚\n",
      "â”‚                                                                                                  â”‚\n",
      "â”‚ The Cursor team begins by defining a code editor as a sophisticated tool tailored for            â”‚\n",
      "â”‚ programming, akin to a word processor. They emphasize that the next decade will see significant  â”‚\n",
      "â”‚ evolution in code editors, focusing on enhancing user experience and productivity through speed  â”‚\n",
      "â”‚ and enjoyment. Their journey from Vim to VS Code, particularly due to the integration of GitHub  â”‚\n",
      "â”‚ Copilot, highlights the emotional connection users develop when AI tools accurately assist in    â”‚\n",
      "â”‚ coding, despite occasional inaccuracies.                                                         â”‚\n",
      "â”‚                                                                                                  â”‚\n",
      "â”‚ A pivotal moment for the team was gaining early access to Gâ€¦                                     â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "âœ… Chunked recursive summarization complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 9. Chunked Recursive Summarization\n",
    "print(\"\\n=== Step 9: Chunked Recursive Summarization ===\")\n",
    "\n",
    "# First, combine all segments into full transcript text\n",
    "full_transcript_df = segments_df.agg(\n",
    "    fc.collect_list(\"segment_text\").alias(\"segment_list\")\n",
    ").select(\n",
    "    \"*\",\n",
    "    fc.text.array_join(fc.col(\"segment_list\"), \" \").alias(\"full_transcript_text\")\n",
    ")\n",
    "\n",
    "print(\"Full transcript assembled\")\n",
    "\n",
    "# Step 1: Chunk the transcript into manageable pieces (using word chunking)\n",
    "chunked_df = full_transcript_df.select(\n",
    "    fc.text.recursive_word_chunk(\n",
    "        fc.col(\"full_transcript_text\"),\n",
    "        chunk_size=1500,  # ~5-7 minutes of speech\n",
    "        chunk_overlap_percentage=10\n",
    "    ).alias(\"chunks\")\n",
    ").explode(\"chunks\").select(\n",
    "    fc.col(\"chunks\").alias(\"chunk_text\")\n",
    ")\n",
    "\n",
    "print(f\"Transcript split into {chunked_df.count()} chunks\")\n",
    "chunked_df.select(fc.text.length(fc.col(\"chunk_text\")).alias(\"chunk_length\")).show(5)\n",
    "\n",
    "# Step 2: Summarize each chunk independently\n",
    "print(\"\\nStep 2: Summarizing individual chunks...\")\n",
    "\n",
    "chunk_summaries_df = chunked_df.select(\n",
    "    \"*\",\n",
    "    fc.semantic.map(\n",
    "        \"Summarize this portion of a Lex Fridman podcast with the Cursor team. Focus on key technical insights, product decisions, and important discussion points. Keep the summary concise but capture the main ideas. Chunk: {chunk_text}\"\n",
    "    ).alias(\"chunk_summary\")\n",
    ")\n",
    "\n",
    "print(\"Individual chunk summaries created\")\n",
    "chunk_summaries_df.select(fc.text.length(fc.col(\"chunk_summary\")).alias(\"summary_length\")).show(5)\n",
    "\n",
    "# Step 3: Combine chunk summaries for recursive summarization\n",
    "print(\"\\nStep 3: Recursive combination of summaries...\")\n",
    "\n",
    "combined_summaries_df = chunk_summaries_df.agg(\n",
    "    fc.collect_list(\"chunk_summary\").alias(\"summary_list\")\n",
    ").select(\n",
    "    \"*\",\n",
    "    fc.text.array_join(fc.col(\"summary_list\"), \" \").alias(\"combined_summaries\")\n",
    ")\n",
    "\n",
    "# Step 4: Create final summary from combined summaries\n",
    "final_summary_df = combined_summaries_df.select(\n",
    "    \"*\",\n",
    "    fc.semantic.map(\n",
    "        \"Create a comprehensive summary of this Lex Fridman podcast episode with the Cursor team (Michael Truell, Arvid Lunnemark, Aman Sanger, Sualeh Asif). Synthesize the key themes, technical insights, product vision, and important discussion points from these chunk summaries. Structure it as a cohesive narrative that captures the essence of the conversation. Combined summaries: {combined_summaries}\"\n",
    "    ).alias(\"final_summary\")\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ“‹ Final Podcast Summary:\")\n",
    "print(\"=\" * 80)\n",
    "final_summary_df.select(fc.col(\"final_summary\")).show()\n",
    "\n",
    "print(\"\\nâœ… Chunked recursive summarization complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 10: Host-Specific Summarization ===\n",
      "Host segments: 505 segments\n",
      "Host total speaking time:\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ total_duration â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ 1903.593506    â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "Host speech aggregated\n",
      "\n",
      "ğŸ™ï¸ Host Analysis - Lex Fridman's Contributions:\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Submitting requests for batch: ff974435-0438-456e-95df-618160c798f3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 229.05req/s, estimated_input_tokens=7445, estimated_output_tokens=512]\n",
      "Awaiting responses for batch ff974435-0438-456e-95df-618160c798f3 (model: gpt-4o-mini): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:09<00:00,  9.71s/res]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ host_analysis                                                                                    â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ Lex Fridman's role as host in the podcast conversation with the Cursor team was marked by his    â”‚\n",
      "â”‚ ability to elicit deep insights and foster meaningful discussions.                               â”‚\n",
      "â”‚                                                                                                  â”‚\n",
      "â”‚ 1) **Thought-Provoking Questions**: Fridman posed questions that challenged the guests to think  â”‚\n",
      "â”‚ critically about their work and the implications of AI in programming. For instance, he asked,   â”‚\n",
      "â”‚ \"What's the point of a code editor?\" and \"How do you win against competitors like Copilot?\"      â”‚\n",
      "â”‚ These questions not only prompted the guests to articulate their vision for Cursor but also      â”‚\n",
      "â”‚ encouraged them to reflect on the broader context of AI's role in software development.          â”‚\n",
      "â”‚                                                                                                  â”‚\n",
      "â”‚ 2) **Personal Insights and Expertise**: Throughout the conversation, Fridman shared his own      â”‚\n",
      "â”‚ experiences and thoughts on programming and AI. He expressed a personal connection to the coding â”‚\n",
      "â”‚ process, likening the interaction with AI tools to a close friendship where the AI completes the â”‚\n",
      "â”‚ programmer's thoughts. His reflections on the emotional aspects of coding and the humanâ€¦         â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "âœ… Host-specific summarization complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 10. Host-Specific Summarization (Lex Fridman)\n",
    "print(\"\\n=== Step 10: Host-Specific Summarization ===\")\n",
    "\n",
    "# Filter segments for the host only (SPEAKER_05 = Lex Fridman)\n",
    "host_segments_df = segments_df.filter(fc.col(\"speaker\") == \"SPEAKER_05\")\n",
    "\n",
    "print(f\"Host segments: {host_segments_df.count()} segments\")\n",
    "\n",
    "# Get host speaking time\n",
    "host_time_df = host_segments_df.agg(fc.sum('duration').alias('total_duration'))\n",
    "print(\"Host total speaking time:\")\n",
    "host_time_df.show()\n",
    "\n",
    "# Aggregate all host speech\n",
    "host_speech_df = host_segments_df.agg(\n",
    "    fc.collect_list(\"segment_text\").alias(\"host_segments_list\")\n",
    ").select(\n",
    "    \"*\",\n",
    "    fc.text.array_join(fc.col(\"host_segments_list\"), \" \").alias(\"host_full_speech\")\n",
    ")\n",
    "\n",
    "print(\"Host speech aggregated\")\n",
    "\n",
    "# Create role-specific host summary focusing on his contributions as interviewer/thought leader\n",
    "host_summary_df = host_speech_df.select(\n",
    "    \"*\",\n",
    "    fc.semantic.map(\n",
    "        \"Analyze Lex Fridman's role as host in this podcast conversation with the Cursor team. Focus on: 1) His most thought-provoking and insightful questions that drove meaningful discussion, 2) Personal insights, experiences, and expertise he shared, 3) How he guided the conversation toward deeper philosophical or technical topics, 4) Broader connections he made between ideas, technology, and humanity, 5) His unique perspective on AI, programming, and the future. Ignore basic facilitation, simple acknowledgments, and routine transitions. Capture his intellectual contributions and interviewing mastery. Host speech: {host_full_speech}\"\n",
    "    ).alias(\"host_analysis\")\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ™ï¸ Host Analysis - Lex Fridman's Contributions:\")\n",
    "print(\"=\" * 80)\n",
    "host_summary_df.select(fc.col(\"host_analysis\")).show()\n",
    "\n",
    "print(\"\\nâœ… Host-specific summarization complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 11: Individual Guest Summaries ===\n",
      "Total guest segments: 1273 segments\n",
      "\n",
      "Guest speaking statistics:\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ guest_name      â”† segment_count â”† total_speaking_time â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ Michael Truell  â”† 223           â”† 1134.180176         â”‚\n",
      "â”‚ Arvid Lunnemark â”† 299           â”† 1439.050781         â”‚\n",
      "â”‚ Aman Sanger     â”† 455           â”† 2743.926025         â”‚\n",
      "â”‚ Sualeh Asif     â”† 295           â”† 1441.587646         â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "ğŸ‘¥ Individual Guest Analyses:\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Submitting requests for batch: f109927f-ad9e-4185-bbf3-a93924b6d75d: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 224.69req/s, estimated_input_tokens=26294, estimated_output_tokens=2048]\n",
      "Awaiting responses for batch f109927f-ad9e-4185-bbf3-a93924b6d75d (model: gpt-4o-mini): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:08<00:00,  2.05s/res]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ guest_name      â”† guest_analysis                                                                 â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
      "â”‚ Arvid Lunnemark â”† Arvid Lunnemark's contributions to the Lex Fridman podcast about Cursor reveal â”‚\n",
      "â”‚                 â”† a deep technical expertise and a forward-thinking perspective on product       â”‚\n",
      "â”‚                 â”† development and AI-assisted programming.                                       â”‚\n",
      "â”‚                 â”†                                                                                â”‚\n",
      "â”‚                 â”† 1. **Technical Expertise and Insights**: Lunnemark emphasizes the importance   â”‚\n",
      "â”‚                 â”† of user experience (UX) in software development, noting that the fun aspect of â”‚\n",
      "â”‚                 â”† programming often correlates with speed. He discusses the nuances of GitHub    â”‚\n",
      "â”‚                 â”† Copilot, highlighting how even when it makes mistakes, the quick feedback loop â”‚\n",
      "â”‚                 â”† allows for a manageable user experience. His insights into next action         â”‚\n",
      "â”‚                 â”† prediction and the verification problem showcase his understanding of the      â”‚\n",
      "â”‚                 â”† complexities involved in coding and AI interactions.                           â”‚\n",
      "â”‚                 â”†                                                                                â”‚\n",
      "â”‚                 â”† 2. **Product Vision and Development Perspectives**: He articulates a vision    â”‚\n",
      "â”‚                 â”† for Cursor that integrates UX design with model development, advocating for a  â”‚\n",
      "â”‚                 â”† holistic approach where the same team works on both aspects. This end-to-end   â”‚\n",
      "â”‚                 â”† development strategy aims to create a seamless interaction betweâ€¦              â”‚\n",
      "â”‚ Michael Truell  â”† 1) Michael Truell's technical expertise is evident in his deep understanding   â”‚\n",
      "â”‚                 â”† of code editors and their evolution. He articulates how code editors serve as  â”‚\n",
      "â”‚                 â”† advanced tools for programmers, akin to word processors, but with unique       â”‚\n",
      "â”‚                 â”† functionalities like error checking and navigation. His insights into the      â”‚\n",
      "â”‚                 â”† structural aspects of programming languages and the potential for code editors â”‚\n",
      "â”‚                 â”† to evolve over the next decade highlight his forward-thinking approach.        â”‚\n",
      "â”‚                 â”†                                                                                â”‚\n",
      "â”‚                 â”† 2) Truell shares a compelling product vision for Cursor, emphasizing the need  â”‚\n",
      "â”‚                 â”† for a code editor that adapts to the advancements in AI and programming        â”‚\n",
      "â”‚                 â”† methodologies. He discusses the shift from traditional coding environments to  â”‚\n",
      "â”‚                 â”† a more integrated and intelligent system that enhances productivity and        â”‚\n",
      "â”‚                 â”† fundamentally changes the act of building software.                            â”‚\n",
      "â”‚                 â”†                                                                                â”‚\n",
      "â”‚                 â”† 3) His narrative includes the origin story of Cursor, rooted in the scaling    â”‚\n",
      "â”‚                 â”† laws from OpenAI and the excitement surrounding the capabilities of models     â”‚\n",
      "â”‚                 â”† like GPT-4. He recounts moments of discoveâ€¦                                    â”‚\n",
      "â”‚ Aman Sanger     â”† Aman Sanger's contributions to the Lex Fridman podcast about Cursor reveal a   â”‚\n",
      "â”‚                 â”† deep technical expertise and a nuanced understanding of AI-assisted            â”‚\n",
      "â”‚                 â”† programming.                                                                   â”‚\n",
      "â”‚                 â”†                                                                                â”‚\n",
      "â”‚                 â”† 1. **Technical Expertise and Insights**: Sanger's background as a Vim user     â”‚\n",
      "â”‚                 â”† transitioning to VS Code highlights his familiarity with coding environments.  â”‚\n",
      "â”‚                 â”† He discusses the impact of AI tools like Copilot on his workflow, emphasizing  â”‚\n",
      "â”‚                 â”† the importance of model capabilities in programming. His insights into scaling â”‚\n",
      "â”‚                 â”† laws and the limitations of current AI models demonstrate a critical           â”‚\n",
      "â”‚                 â”† understanding of the underlying mechanics of AI and programming.               â”‚\n",
      "â”‚                 â”†                                                                                â”‚\n",
      "â”‚                 â”† 2. **Product Vision and Development Perspectives**: Sanger articulates a clear â”‚\n",
      "â”‚                 â”† vision for Cursor, suggesting that the product must evolve rapidly to remain   â”‚\n",
      "â”‚                 â”† relevant. He believes that each advancement in AI capabilities unlocks new     â”‚\n",
      "â”‚                 â”† features, making it essential for Cursor to innovate continuously. His         â”‚\n",
      "â”‚                 â”† perspective on the agility of startups versus larger companies like Microsoft  â”‚\n",
      "â”‚                 â”† underscores theâ€¦                                                               â”‚\n",
      "â”‚ Sualeh Asif     â”† Sualeh Asif's contributions to the Lex Fridman podcast about Cursor reveal a   â”‚\n",
      "â”‚                 â”† deep technical expertise and a visionary perspective on product development.   â”‚\n",
      "â”‚                 â”†                                                                                â”‚\n",
      "â”‚                 â”† 1) **Technical Expertise and Insights**: Sualeh emphasizes the evolution of AI â”‚\n",
      "â”‚                 â”† products, particularly highlighting Copilot as a significant milestone in      â”‚\n",
      "â”‚                 â”† AI-assisted programming. He discusses the importance of capabilities over      â”‚\n",
      "â”‚                 â”† features, suggesting that as language models improve, they should be able to   â”‚\n",
      "â”‚                 â”† understand and edit code more intuitively. His insights into the technical     â”‚\n",
      "â”‚                 â”† challenges of integrating AI with programming tools reflect a strong grasp of  â”‚\n",
      "â”‚                 â”† both AI and software development.                                              â”‚\n",
      "â”‚                 â”†                                                                                â”‚\n",
      "â”‚                 â”† 2) **Product Vision and Development Perspectives**: Sualeh articulates a clear â”‚\n",
      "â”‚                 â”† vision for Cursor, driven by personal frustration with existing tools. He      â”‚\n",
      "â”‚                 â”† expresses a desire for innovative features that enhance the coding experience, â”‚\n",
      "â”‚                 â”† such as the ability for models to edit code and suggest next steps seamlessly. â”‚\n",
      "â”‚                 â”† His focus on creating tools for developerâ€¦                                     â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "âœ… Individual guest summaries complete!\n",
      "\n",
      "âœ… All processing complete with comprehensive summarization pipeline!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 11. Individual Guest Summaries\n",
    "print(\"\\n=== Step 11: Individual Guest Summaries ===\")\n",
    "\n",
    "# Create a mapping of guest speakers and their names for the summaries\n",
    "\n",
    "# Filter guest segments and aggregate speech for each guest\n",
    "guest_segments_df = segments_df.filter(\n",
    "    (fc.col(\"speaker\") != \"SPEAKER_05\") & (fc.col(\"speaker\") != \"null\")  # Exclude host and null speakers\n",
    ")\n",
    "\n",
    "print(f\"Total guest segments: {guest_segments_df.count()} segments\")\n",
    "\n",
    "# Group by speaker and aggregate their speech\n",
    "guest_speech_df = guest_segments_df.group_by(\"speaker\").agg(\n",
    "    fc.collect_list(\"segment_text\").alias(\"speech_segments\"),\n",
    "    fc.count(\"*\").alias(\"segment_count\"),\n",
    "    fc.sum(\"duration\").alias(\"total_speaking_time\")\n",
    ").select(\n",
    "    \"*\",\n",
    "    fc.text.array_join(fc.col(\"speech_segments\"), \" \").alias(\"full_speech\")\n",
    ")\n",
    "\n",
    "# Add guest names to the dataframe\n",
    "guest_with_names_df = guest_speech_df.select(\n",
    "    \"*\",\n",
    "    fc.when(fc.col(\"speaker\") == \"SPEAKER_02\", fc.lit(\"Michael Truell\"))\n",
    "    .when(fc.col(\"speaker\") == \"SPEAKER_03\", fc.lit(\"Arvid Lunnemark\"))\n",
    "    .when(fc.col(\"speaker\") == \"SPEAKER_01\", fc.lit(\"Aman Sanger\"))\n",
    "    .when(fc.col(\"speaker\") == \"SPEAKER_04\", fc.lit(\"Sualeh Asif\"))\n",
    "    .alias(\"guest_name\")\n",
    ")\n",
    "\n",
    "# filter out noisy speakers\n",
    "guest_with_names_df = guest_with_names_df.filter(\n",
    "    fc.col(\"segment_count\") > 10\n",
    ")\n",
    "\n",
    "print(\"\\nGuest speaking statistics:\")\n",
    "guest_with_names_df.select(\n",
    "    fc.col(\"guest_name\"),\n",
    "    fc.col(\"segment_count\"),\n",
    "    fc.col(\"total_speaking_time\")\n",
    ").show()\n",
    "\n",
    "# Create guest-specific summaries focusing on their expertise and contributions\n",
    "guest_summaries_df = guest_with_names_df.select(\n",
    "    \"*\",\n",
    "    fc.semantic.map(\n",
    "        \"Analyze this guest's contributions to the Lex Fridman podcast about Cursor. Focus on: 1) Their specific technical expertise and insights shared, 2) Product vision and development perspectives they brought, 3) Unique experiences and stories they told, 4) Their role and contributions to the Cursor team/company, 5) Technical innovations or solutions they discussed, 6) Their perspective on AI-assisted programming and the future of coding. Capture their individual voice and expertise. Guest: {guest_name}. Speech: {full_speech}\"\n",
    "    ).alias(\"guest_analysis\")\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ‘¥ Individual Guest Analyses:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Show each guest's summary\n",
    "guest_summaries_df.select(\n",
    "    fc.col(\"guest_name\"),\n",
    "    fc.col(\"guest_analysis\")\n",
    ").show()\n",
    "\n",
    "print(\"\\nâœ… Individual guest summaries complete!\")\n",
    "\n",
    "# Clean up\n",
    "session.stop()\n",
    "print(\"\\nâœ… All processing complete with comprehensive summarization pipeline!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
