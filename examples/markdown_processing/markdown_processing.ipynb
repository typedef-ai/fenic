{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import fenic as fc\n",
    "\n",
    "config = fc.SessionConfig(\n",
    "    app_name=\"markdown_processing\",\n",
    "    semantic=fc.SemanticConfig(\n",
    "        language_models= {\n",
    "            \"mini\": fc.OpenAIModelConfig(\n",
    "                model_name=\"gpt-4o-mini\",\n",
    "                rpm=500,\n",
    "                tpm=200_000\n",
    "            )\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "# Initialize fenic session\n",
    "session = fc.Session.get_or_create(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the academic paper markdown content from file\n",
    "paper_path = Path(\"attention_is_all_you_need.md\")\n",
    "with open(paper_path, 'r', encoding='utf-8') as f:\n",
    "    paper_content = f.read()\n",
    "\n",
    "# Create DataFrame with the paper content as a single row\n",
    "df = session.create_dataframe({\n",
    "    \"paper_title\": [\"Attention Is All You Need\"],\n",
    "    \"content\": [paper_content]\n",
    "})\n",
    "\n",
    "# Cast content to MarkdownType to enable markdown-specific functions\n",
    "df = df.select(\n",
    "    fc.col(\"paper_title\"),\n",
    "    fc.col(\"content\").cast(fc.MarkdownType).alias(\"markdown\")\n",
    ")\n",
    "\n",
    "print(\"=== PAPER LOADED ===\")\n",
    "result = df.select(fc.col('paper_title')).to_polars()\n",
    "print(f\"Paper: {result['paper_title'][0]}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate Table of Contents using markdown.generate_toc()\n",
    "toc_df = df.select(\n",
    "    fc.col(\"paper_title\"),\n",
    "    fc.markdown.generate_toc(fc.col(\"markdown\")).alias(\"toc\")\n",
    ")\n",
    "\n",
    "toc_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Extract all document sections and convert to structured DataFrame\n",
    "sections_df = df.select(\n",
    "    fc.col(\"paper_title\"),\n",
    "    fc.markdown.generate_toc(fc.col(\"markdown\")).alias(\"toc\"),\n",
    "    # Extract sections up to level 2 headers, returning array of section objects\n",
    "    fc.markdown.extract_header_chunks(fc.col(\"markdown\"), header_level=2).alias(\"sections\")\n",
    ").explode(\"sections\").unnest(\"sections\")  # Convert array to rows and flatten struct\n",
    "\n",
    "sections_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Filter for specific section (References) and parse its content\n",
    "references_df = sections_df.filter(\n",
    "    fc.col(\"heading\").contains(\"References\")\n",
    ")\n",
    "\n",
    "# Split references content on [1], [2], etc. patterns to separate individual citations\n",
    "references_df.select(\n",
    "    fc.text.split(fc.col(\"content\"), r\"\\[\\d+\\]\").alias(\"references\")\n",
    ").explode(\"references\").show()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Extract references using JSON + jq approach\n",
    "# Convert the original document to JSON structure\n",
    "document_json_df = df.select(\n",
    "    fc.col(\"paper_title\"),\n",
    "    fc.markdown.to_json(fc.col(\"markdown\")).alias(\"document_json\")\n",
    ")\n",
    "\n",
    "# Extract individual references using pure jq\n",
    "# References are nested under \"7 Conclusion\" -> \"References\" heading\n",
    "individual_refs_df = document_json_df.select(\n",
    "    fc.col(\"paper_title\"),\n",
    "    fc.json.jq(\n",
    "        fc.col(\"document_json\"),\n",
    "        # Navigate to References section and split text into individual citations\n",
    "        '.children[-1].children[] | select(.type == \"heading\" and (.content[0].text == \"References\")) | .children[0].content[0].text | split(\"\\\\n\") | .[]'\n",
    "    ).alias(\"reference_text\")\n",
    ").explode(\"reference_text\").select(\n",
    "    fc.col(\"paper_title\"),\n",
    "    fc.col(\"reference_text\").cast(fc.StringType).alias(\"reference_text\")\n",
    ").filter(\n",
    "    fc.col(\"reference_text\") != \"\"\n",
    ")\n",
    "\n",
    "individual_refs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract reference number and content using text.extract() with template\n",
    "print(\"Extracting reference numbers and content using text.extract():\")\n",
    "parsed_refs_df = individual_refs_df.select(\n",
    "    fc.col(\"paper_title\"),\n",
    "    fc.text.extract(\n",
    "        fc.col(\"reference_text\"),\n",
    "        \"[${ref_number:none}] ${content:none}\"\n",
    "    ).alias(\"parsed_ref\")\n",
    ").select(\n",
    "    fc.col(\"paper_title\"),\n",
    "    fc.col(\"parsed_ref\").get_item(\"ref_number\").alias(\"reference_number\"),\n",
    "    fc.col(\"parsed_ref\").get_item(\"content\").alias(\"citation_content\")\n",
    ")\n",
    "\n",
    "print(\"References with separated numbers and content:\")\n",
    "parsed_refs_df.show()\n",
    "print()\n",
    "\n",
    "# Clean up session resources\n",
    "session.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
