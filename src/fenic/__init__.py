"""Fenic is an opinionated, PySpark-inspired DataFrame framework for building production AI and agentic applications."""

from fenic.api import (
    AnthropicModelConfig,
    Catalog,
    CloudConfig,
    Column,
    ColumnOrName,
    DataFrame,
    DataFrameReader,
    DataFrameWriter,
    GoogleGLAModelConfig,
    GoogleVertexModelConfig,
    GroupedData,
    Lineage,
    OpenAIModelConfig,
    SemanticConfig,
    SemanticExtensions,
    Session,
    SessionConfig,
    array,
    array_agg,
    array_contains,
    array_size,
    asc,
    asc_nulls_first,
    asc_nulls_last,
    avg,
    coalesce,
    col,
    collect_list,
    count,
    desc,
    desc_nulls_first,
    desc_nulls_last,
    embedding,
    first,
    json,
    lit,
    markdown,
    max,
    mean,
    min,
    semantic,
    stddev,
    struct,
    sum,
    text,
    udf,
    when,
)
from fenic.core import (
    ArrayType,
    BooleanType,
    ClassifyExample,
    ClassifyExampleCollection,
    ColumnField,
    DataLike,
    DataLikeType,
    DataType,
    DocumentPathType,
    DoubleType,
    EmbeddingType,
    ExtractSchema,
    ExtractSchemaField,
    ExtractSchemaList,
    FloatType,
    HtmlType,
    IntegerType,
    JoinExample,
    JoinExampleCollection,
    JsonType,
    KeyPoints,
    LMMetrics,
    MapExample,
    MapExampleCollection,
    MarkdownType,
    OperatorMetrics,
    Paragraph,
    PredicateExample,
    PredicateExampleCollection,
    QueryMetrics,
    QueryResult,
    RMMetrics,
    Schema,
    SemanticSimilarityMetric,
    StringType,
    StructField,
    StructType,
    TranscriptType,
)
from fenic.logging import configure_logging

__all__ = [
    # Session
    "Session",
    "SessionConfig",
    "CloudConfig",
    "OpenAIModelConfig",
    "AnthropicModelConfig",
    "GoogleGLAModelConfig",
    "GoogleVertexModelConfig",
    "SemanticConfig",
    # IO
    "DataFrameReader",
    "DataFrameWriter",
    # DataFrame
    "DataFrame",
    "GroupedData",
    "SemanticExtensions",
    # Column
    "Column",
    "ColumnOrName",
    # Catalog
    "Catalog",
    # Types
    "ArrayType",
    "BooleanType",
    "ColumnField",
    "DataType",
    "DocumentPathType",
    "DoubleType",
    "EmbeddingType",
    "ExtractSchema",
    "ExtractSchemaField",
    "ExtractSchemaList",
    "FloatType",
    "HtmlType",
    "IntegerType",
    "JsonType",
    "KeyPoints",
    "MapExample",
    "MapExampleCollection",
    "MarkdownType",
    "PredicateExample",
    "PredicateExampleCollection",
    "Schema",
    "ClassifyExample",
    "ClassifyExampleCollection",
    "JoinExample",
    "JoinExampleCollection",
    "Paragraph",
    "Schema",
    "SemanticSimilarityMetric",
    "StringType",
    "StructField",
    "StructType",
    "TranscriptType",
    # Functions
    "semantic",
    "text",
    "json",
    "markdown",
    "embedding",
    "array",
    "array_agg",
    "array_contains",
    "array_size",
    "asc",
    "asc_nulls_first",
    "asc_nulls_last",
    "avg",
    "coalesce",
    "collect_list",
    "count",
    "desc",
    "desc_nulls_first",
    "desc_nulls_last",
    "first",
    "max",
    "mean",
    "min",
    "struct",
    "sum",
    "stddev",
    "udf",
    "when",
    "col",
    "lit",
    # Lineage
    "Lineage",
    # Metrics
    "QueryMetrics",
    "LMMetrics",
    "RMMetrics",
    "OperatorMetrics",
    # Error
    "InvalidExampleCollectionError",
    # Logging
    "configure_logging",
    # QueryResult
    "DataLike",
    "DataLikeType",
    "QueryResult",
]
